{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Vg-SqUlt_nXa",
        "outputId": "bf213db5-64e5-45e6-b4df-b82c1bcb6459",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'wikiauto': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!rm -d -r wikiauto"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/tomm2000/wikiauto"
      ],
      "metadata": {
        "id": "oeOJz14d__YP",
        "outputId": "e0bb1b60-77cc-4faf-e8f8-18d2a0a28b65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'wikiauto'...\n",
            "remote: Enumerating objects: 61, done.\u001b[K\n",
            "remote: Counting objects: 100% (61/61), done.\u001b[K\n",
            "remote: Compressing objects: 100% (44/44), done.\u001b[K\n",
            "remote: Total 61 (delta 30), reused 45 (delta 14), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (61/61), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yEpRIgZD_nXc",
        "outputId": "d1a79c82-be8c-480c-9567-6363f5c435e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.insert(0, '/content/wikiauto/')"
      ],
      "metadata": {
        "id": "byeuYqXTAPWG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tMamRpRb_nXd",
        "outputId": "a54fb73f-d4da-4ecc-95ff-7cb12d6ef817",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda\n"
          ]
        }
      ],
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from vocab import vocab, END_TOKEN, START_TOKEN, PADDING_TOKEN, UNKNOWN_TOKEN\n",
        "from helpers import readLines\n",
        "from load_data import load_data_evaluate, load_data_training, getInputSizeAverage\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import json\n",
        "\n",
        "ENCODER_INPUT_SIZE = 20\n",
        "DECODER_OUTPUT_SIZE = 75\n",
        "BATCH_SIZE = 5\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"device: {device}\")\n",
        "\n",
        "base_path = \"/content/drive/MyDrive/ColabData\"\n",
        "# device = \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rz-0w0LK_nXe"
      },
      "outputs": [],
      "source": [
        "# from load_data import getInputSizeAverage\n",
        "\n",
        "# print(getInputSizeAverage())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZBph-eU_nXg"
      },
      "source": [
        "# ENCODER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "VwOghJo5_nXi"
      },
      "outputs": [],
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "  def __init__(self, type_vocab, value_vocab, hidden_size, embedding_size):\n",
        "    super(EncoderRNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    self.typeEmbedding = nn.Embedding(len(type_vocab), embedding_size, device=device)\n",
        "    self.valueEmbedding = nn.Embedding(len(value_vocab), embedding_size, device=device)\n",
        "    self.positionEmbedding = nn.Embedding(ENCODER_INPUT_SIZE, 10, device=device)\n",
        "    \n",
        "    self.gru = nn.GRU(embedding_size * 2 + 10, self.hidden_size)\n",
        "\n",
        "  def forward(self, inputs, hidden):\n",
        "    E_type_out = self.typeEmbedding(inputs[0])\n",
        "    E_value_out = self.valueEmbedding(inputs[1])\n",
        "    E_pos_out = self.positionEmbedding(inputs[2])\n",
        "\n",
        "    output = torch.cat((E_type_out, E_pos_out, E_value_out), dim=1).view(1, BATCH_SIZE, -1)\n",
        "\n",
        "    output, hidden = self.gru(output, hidden)\n",
        "    return output, hidden\n",
        "\n",
        "  def initHidden(self):\n",
        "    return torch.zeros(1, BATCH_SIZE, self.hidden_size, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjOZmSDG_nXj"
      },
      "source": [
        "# ATTENTION DECODER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hH3FehyM_nXk"
      },
      "outputs": [],
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "  def __init__(self, hidden_size, output_vocab_size, dropout_p=0.1):\n",
        "    super(AttnDecoderRNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_vocab_size = output_vocab_size\n",
        "    self.dropout_p = dropout_p\n",
        "\n",
        "    self.embedding = nn.Embedding(self.output_vocab_size, self.hidden_size)\n",
        "    self.attn = nn.Linear(self.hidden_size * 2, ENCODER_INPUT_SIZE)\n",
        "    self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "    self.dropout = nn.Dropout(self.dropout_p)\n",
        "    self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "    self.out = nn.Linear(self.hidden_size, self.output_vocab_size)\n",
        "\n",
        "  def forward(self, input, hidden, encoder_outputs):\n",
        "    embedded = self.embedding(input).view(1, BATCH_SIZE, -1)\n",
        "    embedded = self.dropout(embedded)\n",
        "\n",
        "    attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "\n",
        "    attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
        "\n",
        "    output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "    output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "    output = F.relu(output)\n",
        "    output, hidden = self.gru(output, hidden)\n",
        "\n",
        "    output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "    return output, hidden, attn_weights\n",
        "\n",
        "  def initHidden(self):\n",
        "    return torch.zeros(1, 1, self.hidden_size, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aH5vwty_nXl"
      },
      "source": [
        "# TIMING & PLOT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2X27yN6x_nXm"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import math\n",
        "import datetime\n",
        "\n",
        "def asMinutes(s):\n",
        "  m = math.floor(s / 60)\n",
        "  s -= m * 60\n",
        "  return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "  now = time.time()\n",
        "  s = now - since\n",
        "  es = s / (percent)\n",
        "  rs = es - s\n",
        "  return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "def showPlot(points):\n",
        "  plt.figure()\n",
        "  fig, ax = plt.subplots()\n",
        "  # this locator puts ticks at regular intervals\n",
        "  loc = ticker.MultipleLocator(base=0.01)\n",
        "  ax.yaxis.set_major_locator(loc)\n",
        "  # ax.set_facecolor('pink')\n",
        "  plt.plot(points)\n",
        "  plt.show()\n",
        "\n",
        "def getPlot(points):\n",
        "  plt.figure()\n",
        "  fig, ax = plt.subplots()\n",
        "  # this locator puts ticks at regular intervals\n",
        "  loc = ticker.MultipleLocator(base=0.01)\n",
        "  ax.yaxis.set_major_locator(loc)\n",
        "  # ax.set_facecolor('pink')\n",
        "  plt.plot(points)\n",
        "  return fig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfXHJIzt_nXn"
      },
      "source": [
        "# INPUT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_IAkIwYs_nXo",
        "outputId": "2db5226e-668b-45b3-a08b-4fb75a89c869",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-5290fca67d3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0moutput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDECODER_OUTPUT_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mpair_amount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000000\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m )\n",
            "\u001b[0;32m/content/wikiauto/load_data.py\u001b[0m in \u001b[0;36mload_data_training\u001b[0;34m(torch, device, vocab_size, batch_size, input_size, output_size, pair_amount, path)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_data_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair_amount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m   \u001b[0mtype_vocab\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{path}/counts/types.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m   \u001b[0mvalue_vocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{path}/counts/values.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m   \u001b[0mtoken_vocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{path}/counts/tokens.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/wikiauto/vocab.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, size)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx2word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUNKNOWN_TOKEN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPADDING_TOKEN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSTART_TOKEN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mEND_TOKEN\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m       \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreadLines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/ColabData/counts/types.txt'"
          ]
        }
      ],
      "source": [
        "type_vocab, value_vocab, token_vocab, pairs = load_data_training(\n",
        "  torch=torch,\n",
        "  device=device,\n",
        "  vocab_size=50000,\n",
        "  batch_size=BATCH_SIZE,\n",
        "  input_size=ENCODER_INPUT_SIZE,\n",
        "  output_size=DECODER_OUTPUT_SIZE,\n",
        "  pair_amount=1000000/BATCH_SIZE,\n",
        "  path=base_path\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kt-LrRmd_nXo"
      },
      "source": [
        "# TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyRbCtGW_nXo"
      },
      "outputs": [],
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "# NOTE: inputs are (1, BATCH_SIZE)\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
        "  encoder_hidden = encoder.initHidden()\n",
        "\n",
        "  encoder_optimizer.zero_grad()\n",
        "  decoder_optimizer.zero_grad()\n",
        "\n",
        "  input_length = input_tensor.size(2) # == PHRASE_SIZE\n",
        "  target_length = target_tensor.size(1)\n",
        "\n",
        "  # NOTE: attention\n",
        "  encoder_outputs = torch.zeros(ENCODER_INPUT_SIZE, encoder.hidden_size, device=device)\n",
        "\n",
        "  loss = 0\n",
        "\n",
        "  for i in range(input_length):\n",
        "    encoder_output, encoder_hidden = encoder(input_tensor[:,:,i], encoder_hidden)\n",
        "    # NOTE: attention\n",
        "    encoder_outputs[i] = encoder_output[0, 0]\n",
        "\n",
        "  decoder_input = torch.tensor([[type_vocab.getID(START_TOKEN)] for _ in range(BATCH_SIZE)], device=device)\n",
        "  decoder_input = decoder_input.view(1, BATCH_SIZE)\n",
        "\n",
        "  decoder_hidden = encoder_hidden\n",
        "\n",
        "  use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "  # use_teacher_forcing = False\n",
        "\n",
        "  if use_teacher_forcing:\n",
        "    # Teacher forcing: Feed the target as the next input\n",
        "    for di in range(target_length):\n",
        "      # NOTE: attention\n",
        "      decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "      # decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "      loss += criterion(decoder_output, target_tensor[:,di])\n",
        "      decoder_input = target_tensor[:, di].view(1, BATCH_SIZE)  # Teacher forcing\n",
        "      \n",
        "  else:\n",
        "    # Without teacher forcing: use its own predictions as the next input\n",
        "    for di in range(target_length):\n",
        "      # NOTE: attention\n",
        "      decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "      # decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "      topv, topi = decoder_output.topk(1)\n",
        "      # decoder_input = topi.squeeze().detach().view(1, BATCH_SIZE)  # detach from history as input\n",
        "      decoder_input = topi\n",
        "\n",
        "      loss += criterion(decoder_output, target_tensor[:,di])\n",
        "\n",
        "  # loss.backward()\n",
        "  loss = loss / target_length\n",
        "  # loss = loss / BATCH_SIZE\n",
        "  loss.backward()\n",
        "\n",
        "  encoder_optimizer.step()\n",
        "  decoder_optimizer.step()\n",
        "\n",
        "  return loss.item() / target_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0tTZx4G_nXp"
      },
      "outputs": [],
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=5e-5):\n",
        "  start = time.time()\n",
        "  plot_losses = []\n",
        "  print_loss_total = 0  # Reset every print_every\n",
        "  plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "  encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "  decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "  training_pairs = [random.choice(pairs) for i in range(n_iters)]\n",
        "  criterion = nn.NLLLoss()\n",
        "\n",
        "  for iter in range(1, n_iters + 1):\n",
        "    training_pair = training_pairs[iter - 1]\n",
        "    input_tensor = training_pair[0]\n",
        "    target_tensor = training_pair[1]\n",
        "\n",
        "    loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "    print_loss_total += loss\n",
        "    plot_loss_total += loss\n",
        "\n",
        "    if iter % print_every == 0:\n",
        "      print_loss_avg = print_loss_total / print_every\n",
        "      print_loss_total = 0\n",
        "      print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                      iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "    if iter % plot_every == 0:\n",
        "      plot_loss_avg = plot_loss_total / plot_every\n",
        "      plot_losses.append(plot_loss_avg)\n",
        "      plot_loss_total = 0\n",
        "  \n",
        "  showPlot(plot_losses) \n",
        "  return getPlot(plot_losses)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73iWON5L_nXp"
      },
      "source": [
        "# EVALUATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iu-24Dm3_nXq"
      },
      "outputs": [],
      "source": [
        "def evaluate(encoder, decoder, input_tensor):\n",
        "  with torch.no_grad():\n",
        "    input_length = input_tensor.size(2) # == max_length\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_outputs = torch.zeros(ENCODER_INPUT_SIZE, encoder.hidden_size, device=device)\n",
        "\n",
        "    for ei in range(input_length):\n",
        "      encoder_output, encoder_hidden = encoder(input_tensor[:,:,ei], encoder_hidden)\n",
        "      encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[type_vocab.getID(START_TOKEN)] for _ in range(BATCH_SIZE)], device=device)\n",
        "    decoder_input = decoder_input.view(1, BATCH_SIZE)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    decoded_words = [[] for _ in range(BATCH_SIZE)]\n",
        "    decoder_attentions = torch.zeros(DECODER_OUTPUT_SIZE, DECODER_OUTPUT_SIZE)\n",
        "\n",
        "    for di in range(DECODER_OUTPUT_SIZE):\n",
        "      decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "      \n",
        "      # TODO: decoder attention\n",
        "      # decoder_attentions[di] = decoder_attention.data\n",
        "      topv, topi = decoder_output.data.topk(1)\n",
        "\n",
        "      # TODO: end tokens dopo fine della frase\n",
        "      for i in range(BATCH_SIZE):\n",
        "        decoded_words[i].append(token_vocab.getWord(topi[i].item()))\n",
        "\n",
        "      decoder_input = topi.squeeze().detach().view(1, BATCH_SIZE)  # detach from history as input\n",
        "\n",
        "    return decoded_words, decoder_attentions[:di + 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggT9p1OY_nXq"
      },
      "source": [
        "# TESTING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yog4T4XL_nXr"
      },
      "outputs": [],
      "source": [
        "\n",
        "encoder = EncoderRNN(type_vocab, value_vocab, 256, 128).to(device)\n",
        "decoder = AttnDecoderRNN(256, len(token_vocab)).to(device)\n",
        "\n",
        "# encoder = torch.load(\"saved_models/encoder_23.08_06.34-40000-iters.pt\", map_location=device)\n",
        "# decoder = torch.load(\"saved_models/decoder_23.08_06.34-40000-iters.pt\", map_location=device)\n",
        "\n",
        "done_epochs = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gA9cCWIW_nXr"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "from math import ceil\n",
        "import os\n",
        "\n",
        "ITERS = 20000\n",
        "EPOCHS = 20\n",
        "SAVE_MODEL_EVERY = 1\n",
        "SAVE_PLOT_EVERY = 1\n",
        "PLOT_TIMES = 1000\n",
        "PRINT_TIMES = 5\n",
        "BATCH_PRINT_SIZE = 5\n",
        "\n",
        "test_input = pairs[0][0]\n",
        "\n",
        "start_time = str(datetime.now().strftime(\"%d.%m_%H.%M\"))\n",
        "output_file = f\"output/out-{start_time}.txt\"\n",
        "# output_file = \"output/out-23.08_01.18.txt\"\n",
        "\n",
        "with open(output_file, 'w', encoding='utf-8') as outfile:\n",
        "  pass\n",
        "\n",
        "for epoch in range(done_epochs, EPOCHS):\n",
        "  losses = [-1]\n",
        "\n",
        "  with open(output_file, 'a', encoding='utf-8') as outfile:\n",
        "    print(f\"----========= CYCLE {epoch+1}/{EPOCHS} - {ITERS*(epoch+1)} iterations =========----\")\n",
        "\n",
        "    plot = trainIters(encoder, decoder, ITERS, print_every=ceil(ITERS/PRINT_TIMES), plot_every=ceil(ITERS/PLOT_TIMES))\n",
        "    outputs, _ = evaluate(encoder, decoder, test_input)\n",
        "\n",
        "    now = datetime.now().strftime(\"%d.%m_%H.%M\")\n",
        "    \n",
        "    outfile.write(f\"\\n----========= CYCLE {epoch+1}/{EPOCHS} - {ITERS*(epoch+1)} iterations =========----\\n\\n\")\n",
        "  \n",
        "    for i in range(min(BATCH_PRINT_SIZE, len(outputs))):\n",
        "      outfile.write(\"----------------------\\n\")\n",
        "      predict = \"\"\n",
        "      target = \"\"\n",
        "      for word in outputs[i]:\n",
        "        predict += str(word) + \" \"\n",
        "      outfile.write(predict + \"\\n\")\n",
        "      outfile.write(\"-.... ↑|predict|↑ ....... ↓|target|↓ ....-\\n\")\n",
        "      for word in pairs[0][1][i]:\n",
        "        target += token_vocab.getWord(word.item()) + \" \"\n",
        "      outfile.write(target + \"\\n\")\n",
        "\n",
        "  if epoch % SAVE_PLOT_EVERY == 0:\n",
        "    plot.savefig(f\"plots/plot-{now}-{(epoch+1)*ITERS}-iters.png\", facecolor ='orange')\n",
        "\n",
        "  if epoch % SAVE_MODEL_EVERY == 0:\n",
        "    torch.save(encoder, f\"saved_models/encoder_{now}-{(epoch+1)*ITERS}-iters.pt\")\n",
        "    torch.save(decoder, f\"saved_models/decoder_{now}-{(epoch+1)*ITERS}-iters.pt\")\n",
        "\n",
        "# os.system('shutdown -s')  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJ4n4HwB_nXr"
      },
      "outputs": [],
      "source": [
        "encoder = torch.load(\"saved_models/encoder_100000-iters.pt\")\n",
        "decoder = torch.load(\"saved_models/decoder_100000-iters.pt\")\n",
        "\n",
        "test_input = pairs[0][0]\n",
        "\n",
        "outputs, _ = evaluate(encoder, decoder, test_input)\n",
        "for i in range(len(outputs)):\n",
        "  print(\"----------------------\")\n",
        "  predict = \"\"\n",
        "  target = \"\"\n",
        "  for word in outputs[i]:\n",
        "    predict += str(word) + \" \"\n",
        "  print(predict)\n",
        "  print(\"-.... ↑|predict|↑ ....... ↓|target|↓ ....-\")\n",
        "  for word in pairs[0][1][i]:\n",
        "    target += token_vocab.getWord(word.item()) + \" \"\n",
        "  print(target)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "cf21a6fff9624ce691a4fad43c68540179d36da31fc4f80138ac9dffe05c7a89"
      }
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}