{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from vocab import vocab, END_TOKEN, START_TOKEN, PADDING_TOKEN, UNKNOWN_TOKEN\n",
    "from helpers import readLines\n",
    "from load_data import load_data\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import json\n",
    "\n",
    "PHRASE_SIZE = 100\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "  def __init__(self, type_vocab, value_vocab, hidden_size, embedding_size):\n",
    "    super(EncoderRNN, self).__init__()\n",
    "    self.hidden_size = hidden_size\n",
    "\n",
    "    self.typeEmbedding = nn.Embedding(len(type_vocab), embedding_size, device=device)\n",
    "    self.valueEmbedding = nn.Embedding(len(value_vocab), embedding_size, device=device)\n",
    "    self.positionEmbedding = nn.Embedding(PHRASE_SIZE, 10, device=device)\n",
    "    \n",
    "    self.gru = nn.GRU(embedding_size * 2 + 10, self.hidden_size)\n",
    "\n",
    "  def forward(self, inputs, hidden):\n",
    "    E_type_out = self.typeEmbedding(inputs[0])\n",
    "    E_value_out = self.valueEmbedding(inputs[1])\n",
    "    E_pos_out = self.positionEmbedding(inputs[2])\n",
    "\n",
    "    output = torch.cat((E_type_out, E_pos_out, E_value_out), dim=1).view(1, BATCH_SIZE, -1)\n",
    "\n",
    "    output, hidden = self.gru(output, hidden)\n",
    "    return output, hidden\n",
    "\n",
    "  def initHidden(self):\n",
    "    return torch.zeros(1, BATCH_SIZE, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DECODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "  def __init__(self, hidden_size, output_size):\n",
    "    super(DecoderRNN, self).__init__()\n",
    "    self.hidden_size = hidden_size\n",
    "\n",
    "    self.embedding = nn.Embedding(output_size, hidden_size, device=device)\n",
    "    \n",
    "    self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "    self.out = nn.Linear(hidden_size, output_size)\n",
    "    self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "  def forward(self, input, hidden):\n",
    "    output = self.embedding(input)\n",
    "\n",
    "    output = F.relu(output)\n",
    "    \n",
    "    output, hidden = self.gru(output, hidden)\n",
    "    output = self.softmax(self.out(output[0]))\n",
    "    return output, hidden\n",
    "\n",
    "  def initHidden(self):\n",
    "    return torch.zeros(1, BATCH_SIZE, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TIMING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "  m = math.floor(s / 60)\n",
    "  s -= m * 60\n",
    "  return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "  now = time.time()\n",
    "  s = now - since\n",
    "  es = s / (percent)\n",
    "  rs = es - s\n",
    "  return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected 10000 pairs out of 39261 available\n",
      "------------------------\n",
      "loading data: 1000/10000 (10.0%)\n",
      "loading data: 2000/10000 (20.0%)\n",
      "loading data: 3000/10000 (30.0%)\n",
      "loading data: 4000/10000 (40.0%)\n",
      "loading data: 5000/10000 (50.0%)\n",
      "loading data: 6000/10000 (60.0%)\n",
      "loading data: 7000/10000 (70.0%)\n",
      "loading data: 8000/10000 (80.0%)\n",
      "loading data: 9000/10000 (90.0%)\n",
      "loading data: 10000/10000 (100.0%)\n",
      "------------------------\n",
      "pairs:  10000\n",
      "batch size: 10, phrase size: 100\n",
      "input shape:  torch.Size([3, 10, 100])\n",
      "output shape:  torch.Size([10, 100])\n"
     ]
    }
   ],
   "source": [
    "type_vocab, value_vocab, token_vocab, pairs = load_data(torch, device, 50000, BATCH_SIZE, PHRASE_SIZE, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "# NOTE: inputs are (1, BATCH_SIZE)\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
    "  encoder_hidden = encoder.initHidden()\n",
    "\n",
    "  encoder_optimizer.zero_grad()\n",
    "  decoder_optimizer.zero_grad()\n",
    "\n",
    "  input_length = input_tensor.size(2) # == PHRASE_SIZE\n",
    "  target_length = target_tensor.size(1)\n",
    "\n",
    "  # NOTE: attention\n",
    "  # encoder_outputs = torch.zeros(PHRASE_SIZE, encoder.hidden_size, device=device)\n",
    "\n",
    "  loss = 0\n",
    "\n",
    "  for i in range(input_length):\n",
    "    encoder_output, encoder_hidden = encoder(input_tensor[:,:,i], encoder_hidden)\n",
    "    # NOTE: attention\n",
    "    # encoder_outputs[i] = encoder_output[0, 0]\n",
    "\n",
    "  decoder_input = torch.tensor([[type_vocab.getID(START_TOKEN)] for _ in range(BATCH_SIZE)], device=device)\n",
    "  decoder_input = decoder_input.view(1, BATCH_SIZE)\n",
    "\n",
    "  decoder_hidden = encoder_hidden\n",
    "\n",
    "  use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "  # use_teacher_forcing = True\n",
    "\n",
    "  if use_teacher_forcing:\n",
    "    # Teacher forcing: Feed the target as the next input\n",
    "    for di in range(target_length):\n",
    "      # NOTE: attention\n",
    "      # decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "      decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "      loss += criterion(decoder_output, target_tensor[:,di])\n",
    "      decoder_input = target_tensor[:, di].view(1, BATCH_SIZE)  # Teacher forcing\n",
    "      \n",
    "  else:\n",
    "    # Without teacher forcing: use its own predictions as the next input\n",
    "    for di in range(target_length):\n",
    "      # NOTE: attention\n",
    "      # decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "      decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "      topv, topi = decoder_output.topk(1)\n",
    "      decoder_input = topi.squeeze().detach().view(1, BATCH_SIZE)  # detach from history as input\n",
    "\n",
    "      loss += criterion(decoder_output, target_tensor[:,di])\n",
    "      \n",
    "      # FIXME\n",
    "      # if decoder_input.item() == END_TOKEN:\n",
    "      #   break\n",
    "\n",
    "  loss.backward()\n",
    "\n",
    "  encoder_optimizer.step()\n",
    "  decoder_optimizer.step()\n",
    "\n",
    "  return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [random.choice(pairs) for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 5s (- 1m 53s) (10 5%) 26.0331\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\tomma\\PROGRAMMING_C\\PYTORCH\\wikiauto3\\model.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tomma/PROGRAMMING_C/PYTORCH/wikiauto3/model.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m encoder \u001b[39m=\u001b[39m EncoderRNN(type_vocab, value_vocab, \u001b[39m256\u001b[39m, \u001b[39m128\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tomma/PROGRAMMING_C/PYTORCH/wikiauto3/model.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m decoder \u001b[39m=\u001b[39m DecoderRNN(\u001b[39m256\u001b[39m, \u001b[39mlen\u001b[39m(token_vocab))\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/tomma/PROGRAMMING_C/PYTORCH/wikiauto3/model.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m trainIters(encoder, decoder, \u001b[39m200\u001b[39;49m, print_every\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, plot_every\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\tomma\\PROGRAMMING_C\\PYTORCH\\wikiauto3\\model.ipynb Cell 13\u001b[0m in \u001b[0;36mtrainIters\u001b[1;34m(encoder, decoder, n_iters, print_every, plot_every, learning_rate)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tomma/PROGRAMMING_C/PYTORCH/wikiauto3/model.ipynb#X16sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m input_tensor \u001b[39m=\u001b[39m training_pair[\u001b[39m0\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tomma/PROGRAMMING_C/PYTORCH/wikiauto3/model.ipynb#X16sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m target_tensor \u001b[39m=\u001b[39m training_pair[\u001b[39m1\u001b[39m]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/tomma/PROGRAMMING_C/PYTORCH/wikiauto3/model.ipynb#X16sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m loss \u001b[39m=\u001b[39m train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tomma/PROGRAMMING_C/PYTORCH/wikiauto3/model.ipynb#X16sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m print_loss_total \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tomma/PROGRAMMING_C/PYTORCH/wikiauto3/model.ipynb#X16sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m plot_loss_total \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\n",
      "\u001b[1;32mc:\\Users\\tomma\\PROGRAMMING_C\\PYTORCH\\wikiauto3\\model.ipynb Cell 13\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tomma/PROGRAMMING_C/PYTORCH/wikiauto3/model.ipynb#X16sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mif\u001b[39;00m use_teacher_forcing:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tomma/PROGRAMMING_C/PYTORCH/wikiauto3/model.ipynb#X16sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m   \u001b[39m# Teacher forcing: Feed the target as the next input\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tomma/PROGRAMMING_C/PYTORCH/wikiauto3/model.ipynb#X16sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m   \u001b[39mfor\u001b[39;00m di \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(target_length):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tomma/PROGRAMMING_C/PYTORCH/wikiauto3/model.ipynb#X16sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     \u001b[39m# NOTE: attention\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tomma/PROGRAMMING_C/PYTORCH/wikiauto3/model.ipynb#X16sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     \u001b[39m# decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/tomma/PROGRAMMING_C/PYTORCH/wikiauto3/model.ipynb#X16sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     decoder_output, decoder_hidden \u001b[39m=\u001b[39m decoder(decoder_input, decoder_hidden)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tomma/PROGRAMMING_C/PYTORCH/wikiauto3/model.ipynb#X16sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m criterion(decoder_output, target_tensor[:,di])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tomma/PROGRAMMING_C/PYTORCH/wikiauto3/model.ipynb#X16sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     decoder_input \u001b[39m=\u001b[39m target_tensor[:, di]\u001b[39m.\u001b[39mview(\u001b[39m1\u001b[39m, BATCH_SIZE)  \u001b[39m# Teacher forcing\u001b[39;00m\n",
      "File \u001b[1;32md:\\PROGRAM_INSTALL\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\tomma\\PROGRAMMING_C\\PYTORCH\\wikiauto3\\model.ipynb Cell 13\u001b[0m in \u001b[0;36mDecoderRNN.forward\u001b[1;34m(self, input, hidden)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tomma/PROGRAMMING_C/PYTORCH/wikiauto3/model.ipynb#X16sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding(\u001b[39minput\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tomma/PROGRAMMING_C/PYTORCH/wikiauto3/model.ipynb#X16sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m output \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(output)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/tomma/PROGRAMMING_C/PYTORCH/wikiauto3/model.ipynb#X16sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m output, hidden \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgru(output, hidden)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tomma/PROGRAMMING_C/PYTORCH/wikiauto3/model.ipynb#X16sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msoftmax(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout(output[\u001b[39m0\u001b[39m]))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tomma/PROGRAMMING_C/PYTORCH/wikiauto3/model.ipynb#X16sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mreturn\u001b[39;00m output, hidden\n",
      "File \u001b[1;32md:\\PROGRAM_INSTALL\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\PROGRAM_INSTALL\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:950\u001b[0m, in \u001b[0;36mGRU.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    948\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[0;32m    949\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 950\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mgru(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[0;32m    951\u001b[0m                      \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[0;32m    952\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    953\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mgru(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[0;32m    954\u001b[0m                      \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "encoder = EncoderRNN(type_vocab, value_vocab, 256, 128).to(device)\n",
    "decoder = DecoderRNN(256, len(token_vocab)).to(device)\n",
    "\n",
    "trainIters(encoder, decoder, 200, print_every=10, plot_every=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf21a6fff9624ce691a4fad43c68540179d36da31fc4f80138ac9dffe05c7a89"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
