{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMamRpRb_nXd",
        "outputId": "a54fb73f-d4da-4ecc-95ff-7cb12d6ef817"
      },
      "outputs": [],
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from helpers.vocab import vocab, END_TOKEN, START_TOKEN, PADDING_TOKEN, UNKNOWN_TOKEN\n",
        "from helpers.helpers import *\n",
        "from helpers.load_data import load_data_evaluate, load_data_training, getInputSizeAverage\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import json\n",
        "from datetime import datetime\n",
        "from math import ceil\n",
        "import os\n",
        "import time\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"device: {device}\")\n",
        "\n",
        "base_path = \"data\"\n",
        "# device = \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ENCODER_INPUT_SIZE = 40 # dimensione dell'input dell'encoder (numero di triple tipo-valore-posizione in input)\n",
        "DECODER_OUTPUT_SIZE = 40 # dimensione dell'output del decoder (lunghezza della frase in output)\n",
        "BATCH_SIZE = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "_IAkIwYs_nXo",
        "outputId": "2db5226e-668b-45b3-a08b-4fb75a89c869"
      },
      "outputs": [],
      "source": [
        "type_vocab, value_vocab, token_vocab, pairs = load_data_training(\n",
        "  torch=torch,\n",
        "  device=device,\n",
        "  vocab_size=5000,\n",
        "  batch_size=BATCH_SIZE,\n",
        "  input_size=ENCODER_INPUT_SIZE,\n",
        "  output_size=DECODER_OUTPUT_SIZE,\n",
        "  pair_amount=100,\n",
        "  path=base_path\n",
        ")\n",
        "\n",
        "def split_data(pairs, train_size=0.8):\n",
        "  train_size = int(train_size * len(pairs))\n",
        "  train_pairs = pairs[:train_size]\n",
        "  test_pairs = pairs[train_size:]\n",
        "  return train_pairs, test_pairs\n",
        "\n",
        "train_pairs, test_pairs = split_data(pairs)\n",
        "\n",
        "# dropout percentuale\n",
        "# criterion se serve logsoftmax\n",
        "\n",
        "# togliere dropout nel test piccolo\n",
        "# se funziona tutto attention weights padding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyRbCtGW_nXo"
      },
      "outputs": [],
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
        "\n",
        "  start = time.time() #-----------------------------------------------\n",
        "  encoder_hidden = encoder.initHidden()\n",
        "\n",
        "  encoder_optimizer.zero_grad()\n",
        "  decoder_optimizer.zero_grad()\n",
        "\n",
        "  input_length = input_tensor.size(2) # == PHRASE_SIZE\n",
        "  target_length = target_tensor.size(1)\n",
        "\n",
        "  print(f\"#1: {asMsecs(time.time() - start)}\") #-----------------------------------------------\n",
        "  start = time.time() #-----------------------------------------------\n",
        "\n",
        "  loss = 0\n",
        "\n",
        "  encoder_outputs, encoder_hidden = encoder(input_tensor, encoder_hidden) #- [BATCH, ENCODER_INPUT_SIZE, HIDDEN]\n",
        "\n",
        "  decoder_input = torch.tensor([type_vocab.getID(START_TOKEN) for _ in range(BATCH_SIZE)], device=device)\n",
        "  decoder_hidden = encoder_hidden\n",
        "\n",
        "  coverage = torch.zeros(BATCH_SIZE, ENCODER_INPUT_SIZE, device=device)\n",
        "  context_vector = None\n",
        "\n",
        "  print(f\"#2: {asMsecs(time.time() - start)}\") #-----------------------------------------------\n",
        "  start = time.time() #-----------------------------------------------\n",
        "\n",
        "  for di in range(target_length):\n",
        "    start_cycle = time.time()\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "    # use_teacher_forcing = True\n",
        "\n",
        "    current_target = target_tensor[:, di] # [BATCH]\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "      # Teacher forcing: Feed the target as the next input\n",
        "      decoder_output, decoder_hidden, context_vector, attn_weights, coverage = decoder(encoder_outputs, decoder_input, decoder_hidden, coverage, context_vector)\n",
        "      decoder_input = current_target\n",
        "        \n",
        "    else:\n",
        "      # Without teacher forcing: use its own predictions as the next input\n",
        "      decoder_output, decoder_hidden, context_vector, attn_weights, coverage = decoder(encoder_outputs, decoder_input, decoder_hidden, coverage, context_vector)\n",
        "      topv, topi = decoder_output.topk(1)\n",
        "      decoder_input = topi.squeeze()\n",
        "\n",
        "    # loss += criterion(decoder_output, current_target)\n",
        "\n",
        "    cycle_time = time.time() - start_cycle\n",
        "    if(cycle_time > 0.2):\n",
        "      print(f\"iter time {di}: {asMsecs(cycle_time)}\")\n",
        "\n",
        "      times = \"\"\n",
        "\n",
        "      for i in range(len(decoder.decoder_times)):\n",
        "        times += f\"[{i}]: {asMsecs(decoder.decoder_times[i])} | \"\n",
        "\n",
        "      print(f\"decoder times: {times}\")\n",
        "\n",
        "      print(\"------------------\")\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "  # print(\"------------------\")\n",
        "  # for i in range(1, len(decoder.decoder_times)):\n",
        "  #   print(f\"avg {i} = {asMsecs(decoder.decoder_times[i] / decoder.decoder_times[0])}\")\n",
        "  #   print(f\"tot {i} = {asMsecs(decoder.decoder_times[i])}\")\n",
        "  #   print(\"------------------\")\n",
        "\n",
        "  # print(\"------------------\")\n",
        "  # for i in range(1, len(decoder.calcAttn.attn_times)):\n",
        "  #   print(f\"avg attn {i} = {asMsecs(decoder.calcAttn.attn_times[i] / decoder.calcAttn.attn_times[0])}\")\n",
        "  #   print(f\"tot attn {i} = {asMsecs(decoder.calcAttn.attn_times[i])}\")\n",
        "  #   print(\"------------------\")\n",
        "\n",
        "  print(f\"#3: {asMsecs(time.time() - start)}\") #-----------------------------------------------\n",
        "  start = time.time() #-----------------------------------------------\n",
        "\n",
        "  raise Exception(\"stop\")\n",
        "  \n",
        "  start = time.time()\n",
        "\n",
        "  loss = loss / target_length\n",
        "  loss.backward()\n",
        "\n",
        "  encoder_optimizer.step()\n",
        "  decoder_optimizer.step()\n",
        "\n",
        "  print(f\"#4: {asMsecs(time.time() - start)}\") #-----------------------------------------------\n",
        "\n",
        "\n",
        "  return loss.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0tTZx4G_nXp"
      },
      "outputs": [],
      "source": [
        "def trainEpoch(encoder, decoder, inputs, print_times=10, plot_times=10000, learning_rate=5e-5):\n",
        "  start = time.time()\n",
        "  plot_losses = []\n",
        "  print_loss_total = 0  # Reset every print_every\n",
        "  plot_loss_total = 0  # Reset every plot_every\n",
        "  epoch_len = len(inputs)\n",
        "  plot_every = max(int(epoch_len / plot_times), 1)\n",
        "  print_every = max(int(epoch_len / print_times), 1)\n",
        "\n",
        "  encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "  decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "  criterion = nn.NLLLoss()\n",
        "\n",
        "  for iter in range(1, epoch_len+1):\n",
        "    # ogni elemento di inputs è una tupla (input, target)\n",
        "    # ogni valore input è un tensore di dimensione [3, batch, encoder_input_size], deve 3 rappresenta (tipo, valore, posizione)\n",
        "    # ogni valore target è un tensore di dimensione [batch, decoder_output_size]\n",
        "\n",
        "    training_pair = inputs[iter-1]\n",
        "    input_tensor = training_pair[0]\n",
        "    target_tensor = training_pair[1]\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "\n",
        "    print(f\"iter {iter} time: {timeSince(start_time, 1)}\")\n",
        "\n",
        "    print_loss_total += loss\n",
        "    plot_loss_total += loss\n",
        "\n",
        "    if iter % print_every == 0:\n",
        "      print_loss_avg = print_loss_total / print_every\n",
        "      print_loss_total = 0\n",
        "      print(f\"{timeSince(start, iter / epoch_len+1)} ({iter} {iter / (epoch_len+1) * 100:.2f}%) {print_loss_avg:.4f}\")\n",
        "\n",
        "    if iter % print_every == 0:\n",
        "      plot_loss_avg = plot_loss_total / plot_every\n",
        "      plot_losses.append(plot_loss_avg)\n",
        "      plot_loss_total = 0\n",
        "\n",
        "  showPlot(plot_losses)\n",
        "  return getPlot(plot_losses)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggT9p1OY_nXq"
      },
      "source": [
        "# TESTING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yog4T4XL_nXr"
      },
      "outputs": [],
      "source": [
        "from models import EncoderRNN, AttnDecoderRNN\n",
        "\n",
        "encoder = EncoderRNN(\n",
        "  type_vocab=type_vocab,\n",
        "  value_vocab=value_vocab,\n",
        "  hidden_size=256,\n",
        "  embedding_size=128,\n",
        "  encoder_input_size=ENCODER_INPUT_SIZE\n",
        ").to(device)\n",
        "\n",
        "decoder = AttnDecoderRNN(\n",
        "  output_vocab_size=len(token_vocab),\n",
        "  hidden_size=256,\n",
        "  embedding_size=128,\n",
        "  batch_size=BATCH_SIZE,\n",
        "  encoder_input_size=ENCODER_INPUT_SIZE,\n",
        "  device=device,\n",
        ").to(device)\n",
        "# decoder = torch.load(\"saved_models/decoder_24.08_14.55-20000-iters.pt\", map_location=device)\n",
        "# encoder = torch.load(\"saved_models/encoder_24.08_14.55-20000-iters.pt\", map_location=device)\n",
        "\n",
        "done_epochs = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gA9cCWIW_nXr"
      },
      "outputs": [],
      "source": [
        "\n",
        "EPOCHS = 1\n",
        "FLAT = 3\n",
        "\n",
        "PLOT_TIMES = 1000\n",
        "PRINT_TIMES = 5\n",
        "BATCH_PRINT_SIZE = 5\n",
        "SAVE_MODEL_EVERY = 1\n",
        "SAVE_PLOT_EVERY = 1\n",
        "\n",
        "start_time = str(datetime.now().strftime(\"%d.%m_%H.%M\"))\n",
        "output_file = f\"{base_path}/output/out-{start_time}.txt\"\n",
        "\n",
        "# with open(output_file, 'w', encoding='utf-8') as outfile: pass\n",
        "\n",
        "prec_loss = 0\n",
        "\n",
        "def saveModel(encoder, decoder, epoch):\n",
        "  torch.save(encoder, f\"{base_path}/models/encoder_{start_time}-ep_{epoch}-iters.pt\")\n",
        "  torch.save(decoder, f\"{base_path}/models/decoder_{start_time}-ep_{epoch}-iters.pt\")\n",
        "\n",
        "def savePlot(plot, epoch):\n",
        "  plot.savefig(f\"{base_path}/plots/plot_{start_time}-ep_{epoch}-iters.png\")\n",
        "\n",
        "def saveOutput(output, target, epoch):\n",
        "  with open(output_file, 'a', encoding='utf-8') as outfile:\n",
        "    for i in range(min(BATCH_PRINT_SIZE, len(output))):\n",
        "      outfile.write(\"----------------------\\n\")\n",
        "      predict = \"\"\n",
        "      target = \"\"\n",
        "      for word in output[i]:\n",
        "        predict += str(word) + \" \"\n",
        "      outfile.write(predict + \"\\n\")\n",
        "      # outfile.write(\"-.... ↑|predict|↑ ....... ↓|target|↓ ....-\\n\")\n",
        "      # for word in pairs[0][1][i]:\n",
        "      #   target += token_vocab.getWord(word.item()) + \" \"\n",
        "      # outfile.write(target + \"\\n\")\n",
        "    \n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "  print(f\"----========= EPOCH {epoch}/{EPOCHS}=========----\")\n",
        "  epoch_start = time.time()\n",
        "  \n",
        "  random.shuffle(pairs)\n",
        "  plot = trainEpoch(encoder, decoder, train_pairs, print_times=PRINT_TIMES, plot_times=PLOT_TIMES)\n",
        "  print(f\"------------------- Trained -------------------\")\n",
        "  curr_loss, sample_start, sample_end = evaluateEpoch(encoder, decoder, test_pairs)\n",
        "\n",
        "  temp_loss = calc_avg_loss(prec_loss, curr_loss)\n",
        "  if(prec_loss < temp_loss):\n",
        "    FLAT -= 1\n",
        "  else:\n",
        "    FLAT = 3\n",
        "  \n",
        "  if(FLAT == 0):\n",
        "    break\n",
        "  \n",
        "  prec_loss = temp_loss\n",
        "\n",
        "  print(f\"------------------- Finished epoch -------------------\")\n",
        "  print(f\"time: {int((time.time() - epoch_start)/60)}min\")\n",
        "  print(f\"loss: {curr_loss}, avg loss: {temp_loss}, flat: {FLAT}\")\n",
        "\n",
        "  # saveOutput(sample_start[0], sample_start[1], epoch)\n",
        "  # saveOutput(sample_end[0], sample_end[1], epoch)\n",
        "\n",
        "  # if epoch % SAVE_PLOT_EVERY == 0:\n",
        "  #   savePlot(plot, epoch, epoch)\n",
        "\n",
        "  # if epoch % SAVE_MODEL_EVERY == 0:\n",
        "  #   saveModel(encoder, decoder, epoch, epoch)\n",
        "\n",
        "\n",
        "  "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "cf21a6fff9624ce691a4fad43c68540179d36da31fc4f80138ac9dffe05c7a89"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
